models:
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-D5F39C2F
          name: Global cross-region model inference requests per minute for Amazon
            Nova 2 Lite
        tpd:
          code: L-AD940EDE
          name: Global cross-region model inference tokens per day for Amazon Nova
            2 Lite
        tpm:
          code: L-71C69B70
          name: Global cross-region model inference tokens per minute for Amazon Nova
            2 Lite
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-F06F1187
          name: Cross-region model inference requests per minute for Amazon Nova 2
            Lite
        tpd:
          code: L-210172B5
          name: Model invocation max tokens per day for Amazon Nova 2 Lite (doubled
            for cross-region calls)
        tpm:
          code: L-C6F5908D
          name: Cross-region model inference tokens per minute for Amazon Nova 2 Lite
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-2-lite-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent:
          code: L-995EBD81
          name: On-demand InvokeModel concurrent requests for Amazon Nova 2 Sonic
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: amazon.nova-2-sonic-v1:0
  provider: Amazon
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-89F8391A
          name: Cross-region model inference requests per minute for Amazon Nova Lite
        tpd: null
        tpm:
          code: L-7C42E72A
          name: Cross-region model inference tokens per minute for Amazon Nova Lite
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-lite-v1:0
  provider: Amazon
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-3F110E0F
          name: Cross-region model inference requests per minute for Amazon Nova Micro
        tpd: null
        tpm:
          code: L-DC7FF66C
          name: Cross-region model inference tokens per minute for Amazon Nova Micro
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-micro-v1:0
  provider: Amazon
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-9AD981E7
          name: Cross-region model inference requests per minute for Amazon Nova Premier
            V1
        tpd:
          code: L-B1D7F4B9
          name: Model invocation max tokens per day for Amazon Nova Premier V1 (doubled
            for cross-region calls)
        tpm:
          code: L-AA7FE948
          name: Cross-region model inference tokens per minute for Amazon Nova Premier
            V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-premier-v1:0
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-premier-v1:0:1000k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-premier-v1:0:20k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-premier-v1:0:8k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-premier-v1:0:mm
  provider: Amazon
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-ED46B8C5
          name: Cross-region model inference requests per minute for Amazon Nova Pro
        tpd: null
        tpm:
          code: L-C0326783
          name: Cross-region model inference tokens per minute for Amazon Nova Pro
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-pro-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AAB0080F
          name: On-demand model inference requests per minute for Amazon Rerank 1.0
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: amazon.rerank-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-879F6850
          name: On-demand model inference requests per minute for Amazon Titan Text
            Embeddings
        tpd: null
        tpm:
          code: L-74B5B793
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Embeddings
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-g1-text-02
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-DF0E34D4
          name: On-demand model inference requests per minute for Amazon Titan Multimodal
            Embeddings G1
        tpd: null
        tpm:
          code: L-ABC24664
          name: On-demand model inference tokens per minute for Amazon Titan Multimodal
            Embeddings G1
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-image-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-embed-image-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-879F6850
          name: On-demand model inference requests per minute for Amazon Titan Text
            Embeddings
        tpd: null
        tpm:
          code: L-74B5B793
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Embeddings
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-text-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-embed-text-v1:2:8k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-26C560CE
          name: On-demand model inference requests per minute for Amazon Titan Text
            Embeddings V2
        tpd: null
        tpm:
          code: L-DE641971
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Embeddings V2
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-text-v2:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-D6269ADB
          name: On-demand model inference requests per minute for Amazon Titan Image
            Generator G1 V2
        tpd: null
        tpm:
          code: L-F1AFB3C9
          name: On-demand model inference tokens per minute for Amazon Titan Image
            Generator G1 V2
  inference_types:
  - PROVISIONED
  - ON_DEMAND
  model_id: amazon.titan-image-generator-v2:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-7DBB06FD
          name: On-demand model inference requests per minute for Amazon Titan Image
            Generator G1
        tpd: null
        tpm:
          code: L-2B715ABD
          name: On-demand model inference tokens per minute for Amazon Titan Image
            Generator G1
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-tg1-large
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-C7438F8F
          name: On-demand model inference requests per minute for Anthropic Claude
            3.5 Haiku
        tpd: null
        tpm:
          code: L-7AB4ABDD
          name: On-demand model inference tokens per minute for Anthropic Claude 3.5
            Haiku
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-252DF594
          name: Cross-Region model inference requests per minute for Anthropic Claude
            3.5 Haiku
        tpd: null
        tpm:
          code: L-4BF37C17
          name: Cross-Region model inference tokens per minute for Anthropic Claude
            3.5 Haiku
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-5-haiku-20241022-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-254CACF4
          name: On-demand model inference requests per minute for Anthropic Claude
            3.5 Sonnet
        tpd: null
        tpm:
          code: L-A50569E5
          name: On-demand model inference tokens per minute for Anthropic Claude 3.5
            Sonnet
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-F457545D
          name: Cross-region model inference requests per minute for Anthropic Claude
            3.5 Sonnet
        tpd: null
        tpm:
          code: L-479B647F
          name: Cross-region model inference tokens per minute for Anthropic Claude
            3.5 Sonnet
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  - INFERENCE_PROFILE
  model_id: anthropic.claude-3-5-sonnet-20240620-v1:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20240620-v1:0:18k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20240620-v1:0:200k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20240620-v1:0:51k
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-79E773B3
          name: On-demand model inference requests per minute for Anthropic Claude
            3.5 Sonnet V2
        tpd: null
        tpm:
          code: L-AD41C330
          name: On-demand model inference tokens per minute for Anthropic Claude 3.5
            Sonnet V2
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-1D3E59A3
          name: Cross-Region model inference requests per minute for Anthropic Claude
            3.5 Sonnet V2
        tpd: null
        tpm:
          code: L-FF8B4E28
          name: Cross-Region model inference tokens per minute for Anthropic Claude
            3.5 Sonnet V2
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-5-sonnet-20241022-v2:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20241022-v2:0:18k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20241022-v2:0:200k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-5-sonnet-20241022-v2:0:51k
  provider: Anthropic
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-3D8CC480
          name: Cross-region model inference requests per minute for Anthropic Claude
            3.7 Sonnet V1
        tpd:
          code: L-9EB71894
          name: Model invocation max tokens per day for Anthropic Claude 3.7 Sonnet
            V1 (doubled for cross-region calls)
        tpm:
          code: L-6E888CC2
          name: Cross-region model inference tokens per minute for Anthropic Claude
            3.7 Sonnet V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-3-7-sonnet-20250219-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-2DC80978
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Haiku
        tpd: null
        tpm:
          code: L-8CE99163
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Haiku
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-616A3F5B
          name: Cross-region model inference requests per minute for Anthropic Claude
            3 Haiku
        tpd: null
        tpm:
          code: L-DCADBC78
          name: Cross-region model inference tokens per minute for Anthropic Claude
            3 Haiku
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-haiku-20240307-v1:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-haiku-20240307-v1:0:200k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-haiku-20240307-v1:0:48k
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-8050DFC8
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Opus
        tpd: null
        tpm:
          code: L-27477D78
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Opus
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-EB15245D
          name: Cross-region model inference requests per minute for Anthropic Claude
            3 Opus
        tpd: null
        tpm:
          code: L-6C86825E
          name: Cross-region model inference tokens per minute for Anthropic Claude
            3 Opus
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-opus-20240229-v1:0
  provider: Anthropic
- inference_types: []
  model_id: anthropic.claude-3-opus-20240229-v1:0:12k
  provider: Anthropic
- inference_types: []
  model_id: anthropic.claude-3-opus-20240229-v1:0:200k
  provider: Anthropic
- inference_types: []
  model_id: anthropic.claude-3-opus-20240229-v1:0:28k
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-F406804E
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Sonnet
        tpd: null
        tpm:
          code: L-4C35BB2A
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Sonnet
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-46591118
          name: Cross-region model inference requests per minute for Anthropic Claude
            3 Sonnet
        tpd: null
        tpm:
          code: L-5DF13F64
          name: Cross-region model inference tokens per minute for Anthropic Claude
            3 Sonnet
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-sonnet-20240229-v1:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-sonnet-20240229-v1:0:200k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-3-sonnet-20240229-v1:0:28k
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-E5084BBA
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Haiku 4.5
        tpd:
          code: L-B5C049AE
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Haiku 4.5
        tpm:
          code: L-9A11C666
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Haiku 4.5
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-CCA5DF70
          name: Cross-region model inference requests per minute for Anthropic Claude
            Haiku 4.5
        tpd:
          code: L-6120CF2D
          name: Model invocation max tokens per day for Anthropic Claude Haiku 4.5
            (doubled for cross-region calls)
        tpm:
          code: L-58BE175A
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Haiku 4.5
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-haiku-4-5-20251001-v1:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-instant-v1:2:100k
  provider: Anthropic
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-7EC72A47
          name: Cross-region model inference requests per minute for Anthropic Claude
            Opus 4.1
        tpd:
          code: L-AB98959C
          name: Model invocation max tokens per day for Anthropic Claude Opus 4.1
            (doubled for cross-region calls)
        tpm:
          code: L-BD85BFCD
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Opus 4.1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-opus-4-1-20250805-v1:0
  provider: Anthropic
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-C99C7EF6
          name: Cross-region model inference requests per minute for Anthropic Claude
            Opus 4 V1
        tpd:
          code: L-28155387
          name: Model invocation max tokens per day for Anthropic Claude Opus 4 V1
            (doubled for cross-region calls)
        tpm:
          code: L-29C2B0A3
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Opus 4 V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-opus-4-20250514-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-58424D95
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Opus 4.5
        tpd:
          code: L-E2985A8E
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Opus 4.5
        tpm:
          code: L-3ABF6ACC
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Opus 4.5
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-27989F42
          name: Cross-region model inference requests per minute for Anthropic Claude
            Opus 4.5
        tpd:
          code: L-F397ECBF
          name: Model invocation max tokens per day for Anthropic Claude Opus 4.5
            (doubled for cross-region calls)
        tpm:
          code: L-7007E9C9
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Opus 4.5
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-opus-4-5-20251101-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-C63AA5DA
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Sonnet 4 V1
        tpd:
          code: L-681C1246
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Sonnet 4 V1
        tpm:
          code: L-97E41E39
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Sonnet 4 V1
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-559DCC33
          name: Cross-region model inference requests per minute for Anthropic Claude
            Sonnet 4 V1
        tpd:
          code: L-22F701C5
          name: Model invocation max tokens per day for Anthropic Claude Sonnet 4
            V1 (doubled for cross-region calls)
        tpm:
          code: L-59759B4A
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Sonnet 4 V1
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-20250514-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-DB84CE56
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Sonnet 4.5 V1
        tpd:
          code: L-BC182137
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Sonnet 4.5 V1
        tpm:
          code: L-27C57EE8
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Sonnet 4.5 V1
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-4A6BFAB1
          name: Cross-region model inference requests per minute for Anthropic Claude
            Sonnet 4.5 V1
        tpd:
          code: L-381AD9EE
          name: Model invocation max tokens per day for Anthropic Claude Sonnet 4.5
            V1 (doubled for cross-region calls)
        tpm:
          code: L-F4DDD3EB
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Sonnet 4.5 V1
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-5-20250929-v1:0
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-v2:0:100k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-v2:0:18k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-v2:1:18k
  provider: Anthropic
- inference_types:
  - PROVISIONED
  model_id: anthropic.claude-v2:1:200k
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-ADB4B3D7
          name: On-demand model inference requests per minute for Cohere Command R
            Plus
        tpd: null
        tpm:
          code: L-FEE1DCB6
          name: On-demand model inference tokens per minute for Cohere Command R Plus
  inference_types:
  - ON_DEMAND
  model_id: cohere.command-r-plus-v1:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-A49CA90F
          name: On-demand model inference requests per minute for Cohere Command R
        tpd: null
        tpm:
          code: L-17F95AA4
          name: On-demand model inference tokens per minute for Cohere Command R
  inference_types:
  - ON_DEMAND
  model_id: cohere.command-r-v1:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-english-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-english-v3:0:512
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-multilingual-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-multilingual-v3:0:512
  provider: Cohere
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-7089DC7D
          name: Global cross-region model inference requests per minute for Cohere
            Embed V4
        tpd:
          code: L-795ADAB0
          name: Global cross-region model inference tokens per day for Cohere Embed
            V4
        tpm:
          code: L-02DFBB76
          name: Global cross-region model inference tokens per minute for Cohere Embed
            V4
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-EB8C1F30
          name: Cross-region model inference requests per minute for Cohere Embed
            V4
        tpd:
          code: L-F1BB08BB
          name: Model invocation max tokens per day for Cohere Embed V4 (doubled for
            cross-region calls)
        tpm:
          code: L-4C3F0FE6
          name: Cross-region model inference tokens per minute for Cohere Embed V4
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: cohere.embed-v4:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-11512E58
          name: On-demand model inference requests per minute for Cohere Rerank 3.5
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.rerank-v3-5:0
  provider: Cohere
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-F52323AB
          name: Cross-region model inference requests per minute for DeepSeek R1 V1
        tpd:
          code: L-6CA2002C
          name: Model invocation max tokens per day for DeepSeek R1 V1 (doubled for
            cross-region calls)
        tpm:
          code: L-06B03968
          name: Cross-region model inference tokens per minute for DeepSeek R1 V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: deepseek.r1-v1:0
  provider: DeepSeek
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-7A5451CB
          name: On-demand model inference requests per minute for DeepSeek V3 V1
        tpd: null
        tpm:
          code: L-30A6895A
          name: On-demand model inference tokens per minute for DeepSeek V3 V1
  inference_types:
  - ON_DEMAND
  model_id: deepseek.v3-v1:0
  provider: DeepSeek
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-999037CA
          name: On-demand model inference requests per minute for Gemma 3 12B
        tpd: null
        tpm:
          code: L-3FD4A73E
          name: On-demand model inference tokens per minute for Gemma 3 12B
  inference_types:
  - ON_DEMAND
  model_id: google.gemma-3-12b-it
  provider: Google
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-5D46C7AF
          name: On-demand model inference requests per minute for Gemma 3 27B
        tpd: null
        tpm:
          code: L-F8729E94
          name: On-demand model inference tokens per minute for Gemma 3 27B
  inference_types:
  - ON_DEMAND
  model_id: google.gemma-3-27b-it
  provider: Google
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-3056DF33
          name: On-demand model inference requests per minute for Gemma 3 4B
        tpd: null
        tpm:
          code: L-73FB8466
          name: On-demand model inference tokens per minute for Gemma 3 4B
  inference_types:
  - ON_DEMAND
  model_id: google.gemma-3-4b-it
  provider: Google
- endpoints:
    base:
      quotas:
        concurrent:
          code: L-3447D96F
          name: On-demand model inference concurrent requests for Luma Ray V2
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: luma.ray-v2:0
  provider: Luma AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-6ED467E8
          name: On-demand model inference requests per minute for Meta Llama 3.1 405B
            Instruct
        tpd: null
        tpm:
          code: L-0F7F5E55
          name: On-demand model inference tokens per minute for Meta Llama 3.1 405B
            Instruct
  inference_types:
  - ON_DEMAND
  model_id: meta.llama3-1-405b-instruct-v1:0
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-ECA5B974
          name: On-demand model inference requests per minute for Meta Llama 3.1 70B
            Instruct
        tpd: null
        tpm:
          code: L-48E55E59
          name: On-demand model inference tokens per minute for Meta Llama 3.1 70B
            Instruct
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-29644EB3
          name: Cross-region model inference requests per minute for Meta Llama 3.1
            70B Instruct
        tpd: null
        tpm:
          code: L-92E68994
          name: Cross-region model inference tokens per minute for Meta Llama 3.1
            70B Instruct
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  - INFERENCE_PROFILE
  model_id: meta.llama3-1-70b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-1-70b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-19A2ED6C
          name: On-demand model inference requests per minute for Meta Llama 3.1 8B
            Instruct
        tpd: null
        tpm:
          code: L-9E79C230
          name: On-demand model inference tokens per minute for Meta Llama 3.1 8B
            Instruct
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-396C5302
          name: Cross-region model inference requests per minute for Meta Llama 3.1
            8B Instruct
        tpd: null
        tpm:
          code: L-9782749C
          name: Cross-region model inference tokens per minute for Meta Llama 3.1
            8B Instruct
  inference_profiles:
  - us
  inference_types:
  - ON_DEMAND
  - INFERENCE_PROFILE
  model_id: meta.llama3-1-8b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-1-8b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama3-2-11b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-2-11b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-A31D2B40
          name: Cross-region model inference requests per minute for Meta Llama 3.2
            1B Instruct
        tpd: null
        tpm:
          code: L-BD9FDA6F
          name: Cross-region model inference tokens per minute for Meta Llama 3.2
            1B Instruct
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama3-2-1b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-2-1b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-6B0A9FAD
          name: Cross-region model inference requests per minute for Meta Llama 3.2
            3B Instruct
        tpd: null
        tpm:
          code: L-0B2687F4
          name: Cross-region model inference tokens per minute for Meta Llama 3.2
            3B Instruct
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama3-2-3b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-2-3b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama3-2-90b-instruct-v1:0
  provider: Meta
- inference_types:
  - PROVISIONED
  model_id: meta.llama3-2-90b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-DEDE703C
          name: Cross-region model inference requests per minute for Meta Llama 3.3
            70B Instruct
        tpd: null
        tpm:
          code: L-0E7AA8B7
          name: Cross-region model inference tokens per minute for Meta Llama 3.3
            70B Instruct
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama3-3-70b-instruct-v1:0
  provider: Meta
- inference_types: []
  model_id: meta.llama3-3-70b-instruct-v1:0:128k
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-46D383AF
          name: On-demand model inference requests per minute for Meta Llama 3 70B
            Instruct
        tpd: null
        tpm:
          code: L-609E24B0
          name: On-demand model inference tokens per minute for Meta Llama 3 70B Instruct
  inference_types:
  - ON_DEMAND
  model_id: meta.llama3-70b-instruct-v1:0
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-320BEFEB
          name: On-demand model inference requests per minute for Meta Llama 3 8B
            Instruct
        tpd: null
        tpm:
          code: L-03A9B835
          name: On-demand model inference tokens per minute for Meta Llama 3 8B Instruct
  inference_types:
  - ON_DEMAND
  model_id: meta.llama3-8b-instruct-v1:0
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-4F18EF2F
          name: Cross-region model inference requests per minute for Meta Llama 4
            Maverick V1
        tpd: null
        tpm:
          code: L-DE3FBBF4
          name: Cross-region model inference tokens per minute for Meta Llama 4 Maverick
            V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama4-maverick-17b-instruct-v1:0
  provider: Meta
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-751B753A
          name: Cross-region model inference requests per minute for Meta Llama 4
            Scout V1
        tpd: null
        tpm:
          code: L-532E6630
          name: Cross-region model inference tokens per minute for Meta Llama 4 Scout
            V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: meta.llama4-scout-17b-instruct-v1:0
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-828C986E
          name: On-demand model inference requests per minute for Minimax M2
        tpd: null
        tpm:
          code: L-A81B7C40
          name: On-demand model inference tokens per minute for Minimax M2
  inference_types:
  - ON_DEMAND
  model_id: minimax.minimax-m2
  provider: MiniMax
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-B14A9603
          name: On-demand model inference requests per minute for Magistral Small
            1.2
        tpd: null
        tpm:
          code: L-D18AC5F7
          name: On-demand model inference tokens per minute for Magistral Small 1.2
  inference_types:
  - ON_DEMAND
  model_id: mistral.magistral-small-2509
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-99F7BDBC
          name: On-demand model inference requests per minute for Ministral 14B 3.0
        tpd: null
        tpm:
          code: L-334E5409
          name: On-demand model inference tokens per minute for Ministral 14B 3.0
  inference_types:
  - ON_DEMAND
  model_id: mistral.ministral-3-14b-instruct
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-DCA37E91
          name: On-demand model inference requests per minute for Ministral 3B 3.0
        tpd: null
        tpm:
          code: L-8A4BEE90
          name: On-demand model inference tokens per minute for Ministral 3B 3.0
  inference_types:
  - ON_DEMAND
  model_id: mistral.ministral-3-3b-instruct
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-2BDF9A55
          name: On-demand model inference requests per minute for Ministral 8B 3.0
        tpd: null
        tpm:
          code: L-3B98F300
          name: On-demand model inference tokens per minute for Ministral 8B 3.0
  inference_types:
  - ON_DEMAND
  model_id: mistral.ministral-3-8b-instruct
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-D9A35062
          name: On-demand model inference requests per minute for Mistral 7B Instruct
        tpd: null
        tpm:
          code: L-02D831F1
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            7B Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-7b-instruct-v0:2
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-3AF844DB
          name: On-demand model inference requests per minute for Mistral Large
        tpd: null
        tpm:
          code: L-01447289
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            Large
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-2402-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-1402869F
          name: On-demand model inference requests per minute for Mistral Large 2407
        tpd: null
        tpm:
          code: L-1C28E1AB
          name: On-demand model inference tokens per minute for Mistral Large 2407
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-2407-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-5B274E24
          name: On-demand model inference requests per minute for Mistral Large 3
        tpd: null
        tpm:
          code: L-C709F563
          name: On-demand model inference tokens per minute for Mistral Large 3
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-3-675b-instruct
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-FD938632
          name: On-demand model inference requests per minute for Mistral Mixtral
            8x7b Instruct
        tpd: null
        tpm:
          code: L-490F4D1F
          name: On-demand model inference tokens per minute for Mistral AI Mixtral
            8X7BB Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mixtral-8x7b-instruct-v0:1
  provider: Mistral AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-674F42D5
          name: Cross-region model inference requests per minute for Mistral Pixtral
            Large 25.02 V1
        tpd: null
        tpm:
          code: L-4B9F76B0
          name: Cross-region model inference tokens per minute for Mistral Pixtral
            Large 25.02 V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: mistral.pixtral-large-2502-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-17AE85BD
          name: On-demand model inference requests per minute for Voxtral Mini 1.0
        tpd: null
        tpm:
          code: L-0B767044
          name: On-demand model inference tokens per minute for Voxtral Mini 1.0
  inference_types:
  - ON_DEMAND
  model_id: mistral.voxtral-mini-3b-2507
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-ACB2FB6A
          name: On-demand model inference requests per minute for Voxtral Small 1.0
        tpd: null
        tpm:
          code: L-930E2896
          name: On-demand model inference tokens per minute for Voxtral Small 1.0
  inference_types:
  - ON_DEMAND
  model_id: mistral.voxtral-small-24b-2507
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-02572418
          name: On-demand model inference requests per minute for Kimi K2 Thinking
        tpd: null
        tpm:
          code: L-03579AC2
          name: On-demand model inference tokens per minute for Kimi K2 Thinking
  inference_types:
  - ON_DEMAND
  model_id: moonshot.kimi-k2-thinking
  provider: Moonshot AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AC7B3FB9
          name: On-demand model inference requests per minute for NVIDIA Nemotron
            Nano 2
        tpd: null
        tpm:
          code: L-33D3627D
          name: On-demand model inference tokens per minute for NVIDIA Nemotron Nano
            2
  inference_types:
  - ON_DEMAND
  model_id: nvidia.nemotron-nano-12b-v2
  provider: NVIDIA
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-2DA9C9CC
          name: On-demand model inference requests per minute for Nemotron Nano 3
            30B
        tpd: null
        tpm:
          code: L-C0663FA3
          name: On-demand model inference tokens per minute for Nemotron Nano 3 30B
  inference_types:
  - ON_DEMAND
  model_id: nvidia.nemotron-nano-3-30b
  provider: NVIDIA
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AC7B3FB9
          name: On-demand model inference requests per minute for NVIDIA Nemotron
            Nano 2
        tpd: null
        tpm:
          code: L-33D3627D
          name: On-demand model inference tokens per minute for NVIDIA Nemotron Nano
            2
  inference_types:
  - ON_DEMAND
  model_id: nvidia.nemotron-nano-9b-v2
  provider: NVIDIA
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-25B50707
          name: On-demand model inference requests per minute for OpenAI GPT OSS 120B
        tpd: null
        tpm:
          code: L-9DC5F595
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 120B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-120b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AF7F0545
          name: On-demand model inference requests per minute for OpenAI GPT OSS 20B
        tpd: null
        tpm:
          code: L-036E14D8
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 20B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-20b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-safeguard-120b
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-65833D55
          name: On-demand model inference requests per minute for GPT OSS Safeguard
            20B
        tpd: null
        tpm:
          code: L-5D8F2F54
          name: On-demand model inference tokens per minute for GPT OSS Safeguard
            20B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-safeguard-20b
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-548A1A32
          name: On-demand model inference requests per minute for Qwen3 235B a22b
            2507 V1
        tpd: null
        tpm:
          code: L-3875BCCF
          name: On-demand model inference tokens per minute for Qwen3 235B a22b 2507
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-235b-a22b-2507-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E880C759
          name: On-demand model inference requests per minute for Qwen3 32B V1
        tpd: null
        tpm:
          code: L-B7C52139
          name: On-demand model inference tokens per minute for Qwen3 32B V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-32b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-66EE6E0B
          name: On-demand model inference requests per minute for Qwen3 Coder 30B
            a3b V1
        tpd: null
        tpm:
          code: L-92F81E14
          name: On-demand model inference tokens per minute for Qwen3 Coder 30B a3b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-30b-a3b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-CBE7E3CD
          name: On-demand model inference requests per minute for Qwen3 Coder 480B
            a35b V1
        tpd: null
        tpm:
          code: L-4D0E44C8
          name: On-demand model inference tokens per minute for Qwen3 Coder 480B a35b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-480b-a35b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-07B3CEEA
          name: On-demand model inference requests per minute for Qwen3 Next 80B A3B
        tpd: null
        tpm:
          code: L-37AB702E
          name: On-demand model inference tokens per minute for Qwen3 Next 80B A3B
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-next-80b-a3b
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-11B56FB0
          name: On-demand model inference requests per minute for Qwen3 VL 235B A22B
        tpd: null
        tpm:
          code: L-46063925
          name: On-demand model inference tokens per minute for Qwen3 VL 235B A22B
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-vl-235b-a22b
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: stability.sd3-5-large-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-0C7F3C72
          name: Cross-region model inference requests per minute for Stable Image
            Conservative Upscale
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-conservative-upscale-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-DB8B3F46
          name: Cross-region model inference requests per minute for Stable Image
            Creative Upscale
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-creative-upscale-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-D3D76E8D
          name: Cross-region model inference requests per minute for Stable Image
            Fast Upscale
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-fast-upscale-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-control-sketch-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-control-structure-v1:0
  provider: Stability AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: stability.stable-image-core-v1:1
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-erase-object-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-inpaint-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-remove-background-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-search-recolor-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-search-replace-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-image-style-guide-v1:0
  provider: Stability AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: stability.stable-image-ultra-v1:1
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-outpaint-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: stability.stable-style-transfer-v1:0
  provider: Stability AI
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-6E046197
          name: Cross-region model inference requests per minute for Twelve Labs Pegasus
        tpd: null
        tpm: null
  inference_profiles:
  - global
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: twelvelabs.pegasus-1-2-v1:0
  provider: TwelveLabs
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-79AAC482
          name: Cross-region model inference requests per minute for Writer AI Palmyra
            X4 V1
        tpd: null
        tpm:
          code: L-FF1F238B
          name: Cross-region model inference tokens per minute for Writer AI Palmyra
            X4 V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: writer.palmyra-x4-v1:0
  provider: Writer
- endpoints:
    us:
      quotas:
        concurrent: null
        rpm:
          code: L-D655BF6C
          name: Cross-region model inference requests per minute for Writer AI Palmyra
            X5 V1
        tpd: null
        tpm:
          code: L-90DFE70F
          name: Cross-region model inference tokens per minute for Writer AI Palmyra
            X5 V1
  inference_profiles:
  - us
  inference_types:
  - INFERENCE_PROFILE
  model_id: writer.palmyra-x5-v1:0
  provider: Writer

models:
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-D5F39C2F
          name: Global cross-region model inference requests per minute for Amazon
            Nova 2 Lite
        tpd:
          code: L-AD940EDE
          name: Global cross-region model inference tokens per day for Amazon Nova
            2 Lite
        tpm:
          code: L-71C69B70
          name: Global cross-region model inference tokens per minute for Amazon Nova
            2 Lite
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-2-lite-v1:0
  provider: Amazon
- endpoints:
    apac:
      quotas:
        concurrent: null
        rpm:
          code: L-89F8391A
          name: Cross-region model inference requests per minute for Amazon Nova Lite
        tpd: null
        tpm:
          code: L-7C42E72A
          name: Cross-region model inference tokens per minute for Amazon Nova Lite
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E386A278
          name: On-demand model inference requests per minute for Amazon Nova Lite
        tpd: null
        tpm:
          code: L-70423BF8
          name: On-demand model inference tokens per minute for Amazon Nova Lite
  inference_profiles:
  - apac
  inference_types:
  - INFERENCE_PROFILE
  - ON_DEMAND
  model_id: amazon.nova-lite-v1:0
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-lite-v1:0:24k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-lite-v1:0:300k
  provider: Amazon
- endpoints:
    apac:
      quotas:
        concurrent: null
        rpm:
          code: L-3F110E0F
          name: Cross-region model inference requests per minute for Amazon Nova Micro
        tpd: null
        tpm:
          code: L-DC7FF66C
          name: Cross-region model inference tokens per minute for Amazon Nova Micro
  inference_profiles:
  - apac
  inference_types:
  - INFERENCE_PROFILE
  model_id: amazon.nova-micro-v1:0
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-micro-v1:0:128k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-micro-v1:0:24k
  provider: Amazon
- endpoints:
    apac:
      quotas:
        concurrent: null
        rpm:
          code: L-ED46B8C5
          name: Cross-region model inference requests per minute for Amazon Nova Pro
        tpd: null
        tpm:
          code: L-C0326783
          name: Cross-region model inference tokens per minute for Amazon Nova Pro
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-F2717A44
          name: On-demand model inference requests per minute for Amazon Nova Pro
        tpd: null
        tpm:
          code: L-CE33604C
          name: On-demand model inference tokens per minute for Amazon Nova Pro
  inference_profiles:
  - apac
  inference_types:
  - INFERENCE_PROFILE
  - ON_DEMAND
  model_id: amazon.nova-pro-v1:0
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-pro-v1:0:24k
  provider: Amazon
- inference_types: []
  model_id: amazon.nova-pro-v1:0:300k
  provider: Amazon
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-E5084BBA
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Haiku 4.5
        tpd:
          code: L-B5C049AE
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Haiku 4.5
        tpm:
          code: L-9A11C666
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Haiku 4.5
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-haiku-4-5-20251001-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-58424D95
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Opus 4.5
        tpd:
          code: L-E2985A8E
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Opus 4.5
        tpm:
          code: L-3ABF6ACC
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Opus 4.5
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-opus-4-5-20251101-v1:0
  provider: Anthropic
- endpoints:
    apac:
      quotas:
        concurrent: null
        rpm:
          code: L-559DCC33
          name: Cross-region model inference requests per minute for Anthropic Claude
            Sonnet 4 V1
        tpd:
          code: L-22F701C5
          name: Model invocation max tokens per day for Anthropic Claude Sonnet 4
            V1 (doubled for cross-region calls)
        tpm:
          code: L-59759B4A
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Sonnet 4 V1
  inference_profiles:
  - apac
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-20250514-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-DB84CE56
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Sonnet 4.5 V1
        tpd:
          code: L-BC182137
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Sonnet 4.5 V1
        tpm:
          code: L-27C57EE8
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Sonnet 4.5 V1
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-5-20250929-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-7089DC7D
          name: Global cross-region model inference requests per minute for Cohere
            Embed V4
        tpd:
          code: L-795ADAB0
          name: Global cross-region model inference tokens per day for Cohere Embed
            V4
        tpm:
          code: L-02DFBB76
          name: Global cross-region model inference tokens per minute for Cohere Embed
            V4
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: cohere.embed-v4:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-7A5451CB
          name: On-demand model inference requests per minute for DeepSeek V3 V1
        tpd: null
        tpm:
          code: L-30A6895A
          name: On-demand model inference tokens per minute for DeepSeek V3 V1
  inference_types:
  - ON_DEMAND
  model_id: deepseek.v3-v1:0
  provider: DeepSeek
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-25B50707
          name: On-demand model inference requests per minute for OpenAI GPT OSS 120B
        tpd: null
        tpm:
          code: L-9DC5F595
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 120B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-120b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AF7F0545
          name: On-demand model inference requests per minute for OpenAI GPT OSS 20B
        tpd: null
        tpm:
          code: L-036E14D8
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 20B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-20b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-548A1A32
          name: On-demand model inference requests per minute for Qwen3 235B a22b
            2507 V1
        tpd: null
        tpm:
          code: L-3875BCCF
          name: On-demand model inference tokens per minute for Qwen3 235B a22b 2507
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-235b-a22b-2507-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E880C759
          name: On-demand model inference requests per minute for Qwen3 32B V1
        tpd: null
        tpm:
          code: L-B7C52139
          name: On-demand model inference tokens per minute for Qwen3 32B V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-32b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-66EE6E0B
          name: On-demand model inference requests per minute for Qwen3 Coder 30B
            a3b V1
        tpd: null
        tpm:
          code: L-92F81E14
          name: On-demand model inference tokens per minute for Qwen3 Coder 30B a3b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-30b-a3b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-CBE7E3CD
          name: On-demand model inference requests per minute for Qwen3 Coder 480B
            a35b V1
        tpd: null
        tpm:
          code: L-4D0E44C8
          name: On-demand model inference tokens per minute for Qwen3 Coder 480B a35b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-480b-a35b-v1:0
  provider: Qwen
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: twelvelabs.pegasus-1-2-v1:0
  provider: TwelveLabs
